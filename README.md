# ğŸ§  Linga Bot â€” AI Grammar Correction System

Linga Bot is a **production-style AI grammar correction system** built with **FastAPI**, combining a **locally fine-tuned T5 model** with a **cloud-based Gemini fallback** for improved accuracy and reliability.

The project demonstrates **end-to-end ML engineering**, from model fine-tuning to secure API deployment and frontend integration.

---

## ğŸš€ Features

- âœ… Fine-tuned **T5-small** model for grammar correction  
- ğŸ” **Automatic fallback**: T5 â†’ Gemini  
- ğŸ” **JWT-based authentication** (register / login)  
- âš¡ FastAPI backend with modular service design  
- ğŸ–¥ï¸ Streamlit frontend for interactive usage  
- ğŸ”’ Secure environment variable handling  
- ğŸ“¦ Easily extensible to OpenAI or other LLMs  

---

## ğŸ—ï¸ Project Structure
```

LINGA\_BOT/  
â”‚  
â”œâ”€â”€ app/ # FastAPI backend  
â”‚ â”œâ”€â”€ auth/ # JWT auth logic  
â”‚ â”œâ”€â”€ db/ # Fake DB (upgradeable)  
â”‚ â”œâ”€â”€ model/ # T5 model wrapper  
â”‚ â”œâ”€â”€ routes/ # API routes  
â”‚ â”œâ”€â”€ services/ # T5, Gemini, auto-fallback  
â”‚ â”œâ”€â”€ utils/ # Security utilities  
â”‚ â””â”€â”€ main.py # App entry point  
â”‚  
â”œâ”€â”€ frontend/  
â”‚ â””â”€â”€ streamlit.py # Streamlit UI  
â”‚  
â”œâ”€â”€ requirements.txt  
â”œâ”€â”€ .env.example  
â””â”€â”€ README.md

```
---

## ğŸ§  Architecture Overview

![Architecture Diagram](images/linga_architecture.png)

**Design principle:**  
> *Local-first inference for cost & latency, cloud fallback for quality.*

---
## ğŸ” Engine Fallback Logic

1. Attempt correction using **T5 (local model)**
2. If output is weak or fails â†’ fallback to **Gemini**
3. Return first successful correction
4. If all engines fail â†’ controlled error response

This makes the system **resilient and cost-aware**.

---

## ğŸ” Authentication Flow

- `POST /register` â†’ create user  
- `POST /login` â†’ receive JWT token  
- Protected routes require:
```

Authorization: Bearer <JWT\_TOKEN>

```
---

## ğŸ“¡ API Endpoints

### Register
```http
POST /register
```

### Login

```http
POST /login
```

### Grammar Correction (Manual Engine)

```http
POST /correct?text=your_text&engine=t5
POST /correct?text=your_text&engine=google
```

### Grammar Correction (Auto Fallback)

```http
POST /correct/auto?text=your_text
```

---

## ğŸ–¥ï¸ Frontend (Streamlit)

Run:

```bash
streamlit run frontend/streamlit.py
```

Features:

-   Login & token handling
    
-   Text input for grammar correction
    
-   Engine selection (`auto`, `t5`, `google`)
    
-   Displays corrected output + engine used
    

---

## âš™ï¸ Environment Variables

Create a `.env` file (DO NOT commit):

```env
GOOGLE_API_KEY=your_google_api_key
JWT_SECRET_KEY=your_secret_key
```

Example file provided:

```
.env.example
```

---

## ğŸ§ª Run Locally

### 1ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 2ï¸âƒ£ Start backend

```bash
uvicorn app.main:app --reload
```

### 3ï¸âƒ£ Open API docs

```arduino
http://127.0.0.1:8000/docs
```

---

## ğŸ§© Tech Stack

-   **Backend**: FastAPI, Python
    
-   **Models**: T5-small (fine-tuned), Gemini
    
-   **Auth**: JWT
    
-   **Frontend**: Streamlit
    
-   **ML**: Hugging Face Transformers
    
-   **Deployment-ready** architecture
    

---

## ğŸ¯ Why This Project Matters

This project demonstrates:

-   ML model fine-tuning & inference
    
-   API-first system design
    
-   Secure auth integration
    
-   Cost-aware LLM usage
    
-   Production-style fallback strategies
    

Built for **real-world usage**, not just demos.

---

## ğŸ”® Future Improvements

-   Replace fake DB with MongoDB / PostgreSQL
    
-   Add engine health checks & quota guards
    
-   Side-by-side engine comparison UI
    
-   OpenAI integration (plug-and-play)
    
-   Dockerized deployment
    

---

## ğŸ‘¤ Author

**Harsha Vardhan Nandineni**  
Final-year CSE | AI & ML Enthusiast  
Focused on ML systems, backend engineering, and production AI


---
